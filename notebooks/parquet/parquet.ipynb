{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet: Acelere sua Análise de Dados e Reduza Custos em Nuvem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalar Parquet, Pandas e Pyarrow\n",
    "%!pip install parquet\n",
    "%!pip install pandas\n",
    "%!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar os pacotes necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DataFrame de exemplo com diversos tipos de dados\n",
    "df = pd.DataFrame({\n",
    "    'Nome': ['Maria', 'John', 'Tonico', 'Mariane'],\n",
    "    'Idade': [25, 30, 35, np.nan],  # Incluindo um valor nulo\n",
    "    'Salário': [50000.50, 60000.75, 70000.00, 80000.25],\n",
    "    'Data_Admissão': pd.to_datetime(['2020-01-15', '2019-05-20', '2018-11-01', '2021-03-10']),\n",
    "    'Descrição': ['Desenvolvedora Python', 'Analista de Dados', 'Cientista de Dados', 'Gerente de Projetos com acentuação çãõ']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyArrow: Uma Solução Completa de Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converta o DataFrame em uma Arrow Table\n",
    "df = pa.Table.from_pandas(df)\n",
    "\n",
    "# Escrevendo o DataFrame para um arquivo Parquet usando pyarrow\n",
    "try:\n",
    "    pq.write_table(df, 'dataset/sample.parquet')\n",
    "    print(\"\\nArquivo Parquet 'dataset/sample.parquet' escrito com sucesso usando pyarrow!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao escrever o arquivo Parquet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler arquivo `Parquet` utilizando pyarrow\n",
    "Pode utilizar o método `read_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo completo com pyarrow\n",
    "try:\n",
    "    # Leia o arquivo Parquet em uma Arrow Table\n",
    "    df = pq.read_table('dataset/sample.parquet')\n",
    "    print(\"\\nDataFrame lido completo com pyarrow:\")\n",
    "    print(df)\n",
    "\n",
    "    # Converte a tabela pyarrow para um DataFrame pandas, se necessário\n",
    "    # df_pandas = df.to_pandas() # Descomente esta linha se precisar de um DataFrame pandas\n",
    "    # print(\"\\nDataFrame lido completo com pandas:\")\n",
    "    # print(df_pandas)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nErro: Arquivo Parquet não encontrado. Certifique-se de que o arquivo 'dataset/sample.parquet' ou 'dataset/sample_fastparquet.parquet' existe no diretório atual.\")\n",
    "except pd.errors.ParserError as pe:\n",
    "    print(f\"\\nErro de parsing do Parquet: {pe}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOutro erro ao ler o arquivo Parquet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler apenas colunas especificas em uma tabela utilizando pyarrow\n",
    "Pode utilizar o método `read_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo apenas as colunas 'Nome' e 'Salário' com pyarrow\n",
    "try:\n",
    "    # Abre o arquivo Parquet\n",
    "    df_colunas_selecionadas = pq.read_table('dataset/sample.parquet', columns=['Nome', 'Salário'])\n",
    "    print(\"\\nTabela com colunas selecionadas (Nome e Salário) com pyarrow:\")\n",
    "    print(df_colunas_selecionadas)\n",
    "\n",
    "    # Utilizando o pandas, se necessário\n",
    "    # df_colunas_selecionadas_pd = pd.read_parquet('dataset/sample.parquet', columns=['Nome', 'Salário'], engine='pyarrow')\n",
    "    # print(df_colunas_selecionadas_pd)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nErro: Arquivo Parquet não encontrado. Certifique-se de que o arquivo 'dataset/sample.parquet' existe no diretório atual.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOutro erro ao ler o arquivo Parquet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionar uma nova coluna e seus valores a uma tabela pyarrow\n",
    "\n",
    "Pode utilizar o método `add_column`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma nova coluna com pyarrow\n",
    "try:\n",
    "    nova_coluna_nome = 'Status'\n",
    "    nova_coluna = pa.array(['Ativo', 'Inativo', 'Ativo', 'Inativo'])\n",
    "\n",
    "    # Verifica se a coluna já existe\n",
    "    if nova_coluna_nome in df.column_names:\n",
    "         print(f\"\\nA coluna '{nova_coluna_nome}' já existe na tabela. Não será adicionada.\")\n",
    "    else:\n",
    "        # Adiciona a nova coluna à tabela\n",
    "        df = df.add_column(len(df.column_names), pa.field(nova_coluna_nome, nova_coluna.type), nova_coluna)\n",
    "\n",
    "        # Converte a tabela pyarrow para um DataFrame pandas para visualização\n",
    "        df_final = df.to_pandas()\n",
    "\n",
    "        print(\"\\nTabela com a nova coluna:\")\n",
    "        print(df_final)\n",
    "\n",
    "        # Escreve a tabela em um arquivo Parquet\n",
    "        pq.write_table(df, 'dataset/output_com_nova_coluna.parquet')\n",
    "\n",
    "        print(\"\\nArquivo Parquet 'dataset/output_com_nova_coluna.parquet' escrito com sucesso!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro ao adicionar a coluna e escrever o arquivo Parquet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterar um valor específico em uma coluna de uma tabela com pyarrow.\n",
    "\n",
    "Embora o processo seja um pouco diferente de como faríamos em um pandas.DataFrame diretamente. A tabela pyarrow é imutável, então você precisará criar um novo array com a modificação e substituir a coluna inteira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterar valor de um indice da coluna com pyarrow\n",
    "try:\n",
    "\n",
    "    # Especificações da alteração\n",
    "    coluna_para_alterar = 'Salário'\n",
    "    indice_do_valor = 1  # Índice do valor a ser alterado (Bob)\n",
    "    novo_valor = 65000\n",
    "\n",
    "    # Verifica se a coluna existe\n",
    "    if coluna_para_alterar not in df.column_names:\n",
    "        print(f\"\\nErro: A coluna '{coluna_para_alterar}' não existe.\")\n",
    "    else:\n",
    "        # Verifica se o índice está dentro do alcance\n",
    "        coluna = df.column(coluna_para_alterar)\n",
    "        if indice_do_valor < 0 or indice_do_valor >= len(coluna):\n",
    "             print(f\"\\nErro: Índice '{indice_do_valor}' fora do alcance da coluna '{coluna_para_alterar}'.\")\n",
    "        else:\n",
    "            # Cria um novo array (cópia) com o valor alterado\n",
    "            novo_array = coluna.to_numpy().copy() # Usamos copy() aqui\n",
    "            novo_array[indice_do_valor] = novo_valor\n",
    "            novo_array = pa.array(novo_array)\n",
    "\n",
    "            # Substitui a coluna original pela nova coluna\n",
    "            df = df.set_column(df.column_names.index(coluna_para_alterar), pa.field(coluna_para_alterar, novo_array.type), novo_array)\n",
    "\n",
    "            print(f\"\\nValor na coluna '{coluna_para_alterar}' no índice '{indice_do_valor}' alterado para '{novo_valor}' com sucesso.\")\n",
    "\n",
    "            # Converte a tabela para um DataFrame pandas para visualização\n",
    "            df_final = df.to_pandas()\n",
    "            print(\"\\nTabela com o valor alterado:\")\n",
    "            print(df_final)\n",
    "\n",
    "\n",
    "            # Escreve a tabela em um novo arquivo Parquet\n",
    "            pq.write_table(df, 'dataset/output_valor_alterado.parquet')\n",
    "            print(\"\\nArquivo Parquet 'dataset/output_valor_alterado.parquet' escrito com sucesso!\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro ao alterar o valor e escrever o arquivo Parquet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluir uma coluna existente de uma tabela com pyarrow.\n",
    "\n",
    "Pode usar o método` remove_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir uma coluna com pyarrow\n",
    "\n",
    "try:\n",
    "    # Nome da coluna a ser removida\n",
    "    coluna_a_remover = 'Salário'\n",
    "\n",
    "    # Verifica se a coluna existe antes de tentar remover\n",
    "    if coluna_a_remover in df.column_names:\n",
    "      # Remove a coluna da tabela\n",
    "        df = df.remove_column(df.column_names.index(coluna_a_remover))\n",
    "        print(f\"\\nA coluna '{coluna_a_remover}' foi removida com sucesso.\")\n",
    "\n",
    "      # Converte a tabela pyarrow para um DataFrame pandas para visualização\n",
    "        df_final = df.to_pandas()\n",
    "\n",
    "        print(\"\\nTabela sem a coluna:\")\n",
    "        print(df_final)\n",
    "\n",
    "        # Escreve a tabela em um novo arquivo Parquet\n",
    "        pq.df(df, 'dataset/output_sem_coluna.parquet')\n",
    "\n",
    "        print(\"\\nArquivo Parquet 'dataset/output_sem_coluna.parquet' escrito com sucesso!\")\n",
    "    else:\n",
    "        print(f\"\\nA coluna '{coluna_a_remover}' não existe na tabela. A remoção não será realizada.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro ao remover a coluna e escrever o arquivo Parquet: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrevendo o DataFrame para um arquivo Parquet usando pandas\n",
    "try:\n",
    "    df.to_parquet('dataset/sample.parquet', engine='pyarrow')\n",
    "    print(\"\\nArquivo Parquet 'dataset/sample.parquet' escrito com sucesso usando pandas!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao escrever o arquivo Parquet: {e}\")\n",
    "\n",
    "# Lendo apenas as colunas 'Nome' e 'Salário' com pandas\n",
    "try:\n",
    "    df_colunas_selecionadas = pd.read_parquet('dataset/sample.parquet', columns=['Nome', 'Salário'], engine='pyarrow')\n",
    "    print(\"\\nDataFrame com colunas selecionadas (Nome e Salário) com pyarrow:\")\n",
    "    print(df_colunas_selecionadas)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nErro: Arquivo Parquet não encontrado. Certifique-se de que o arquivo 'dataset/sample.parquet' ou 'dataset/sample_fastparquet.parquet' existe no diretório atual.\")\n",
    "except pd.errors.ParserError as pe:\n",
    "    print(f\"\\nErro de parsing do Parquet: {pe}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOutro erro ao ler o arquivo Parquet: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
